{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351dff79-8cf4-4d47-bdd8-42c444fb6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import praw\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c285ad7-5e00-4fed-9cd5-549afb0a2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyDz18HEL5Y6BRVJPzpZQkpJDSXPwL6B5P8\"\n",
    "SEARCH_ENGINE_ID = \"57a664a53af214b7e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e1a115-4998-4e98-a7f2-63c017c1f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PRAW with your Reddit credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"Pr-co5-36bkZzmAr-amBZg\",\n",
    "    client_secret=\"LhMeEf7Hy9LJS20uJWCwQQWYGWunlQ\",\n",
    "    user_agent=\"Alternative-Bag-3334\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8409ded-941c-41db-b4ca-a64bb59c0fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit_urls(api_key, search_engine_id, query, max_results=20):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    reddit_urls = []\n",
    "    for start in range(1, max_results + 1, 10):  # Incrementing by 10 for pagination\n",
    "        params = {\n",
    "            'key': api_key,\n",
    "            'cx': search_engine_id,\n",
    "            'q': f\"{query} site:reddit.com\",\n",
    "            'num': 10,\n",
    "            'start': start,\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            results = response.json()\n",
    "            for item in results.get('items', []):\n",
    "                link = item.get('link')\n",
    "                if 'reddit.com' in link:\n",
    "                    reddit_urls.append(link)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            break  # Stop if there's an error\n",
    "    return reddit_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849d6f80-092b-4d81-8b4e-17a1e9fbccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  What people think on Trump winning the election\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit URLs:\n",
      "https://www.reddit.com/r/AskFeminists/comments/1e447os/how_do_you_think_womens_rights_will_be_changed_if/\n",
      "https://www.reddit.com/r/decadeology/comments/1ahaowj/do_you_think_there_will_be_a_civil_war_after_the/\n",
      "https://www.reddit.com/r/Ask_Politics/comments/1f3ee21/what_is_actually_wrong_with_voting_for_the_green/\n",
      "https://www.reddit.com/r/PoliticalDiscussion/comments/1dvimu4/if_trump_wins_the_election_do_you_think_there/\n",
      "https://www.reddit.com/r/lexfridman/comments/1f12fd8/trump_vs_harris_who_wins_if_election_is_held_today/\n",
      "https://www.reddit.com/r/PoliticalDiscussion/comments/1d85okb/realistically_what_happens_if_trump_wins_in/\n",
      "https://www.reddit.com/r/Ask_Politics/comments/1elhs11/why_is_this_election_predicted_to_be_so_close/\n",
      "https://www.reddit.com/r/PoliticalDiscussion/comments/1dels8t/how_likely_do_you_think_it_is_that_donald_trump/\n",
      "https://www.reddit.com/r/PoliticalDiscussion/comments/1eq1o5a/do_you_think_there_would_be_a_january_6_20_civil/\n",
      "https://www.reddit.com/r/PoliticalDiscussion/comments/1fassk6/if_trump_ultimately_wins_the_election_what_will/\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter your question: \")\n",
    "reddit_urls = get_reddit_urls(API_KEY, SEARCH_ENGINE_ID, query, max_results=5)\n",
    "\n",
    "if reddit_urls:\n",
    "    print(\"Reddit URLs:\")\n",
    "    for url in reddit_urls:\n",
    "        print(url)\n",
    "else:\n",
    "    print(\"No Reddit URLs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046bd52c-16d5-49e3-a0e7-7bb04ddca743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_utc_to_datetime(utc_timestamp):\n",
    "    \"\"\"Convert UTC timestamp to readable date and time.\"\"\"\n",
    "    return datetime.fromtimestamp(utc_timestamp).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dea16ed-4545-497b-9ead-0619c4865af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_comments(submission, max_comments=10):\n",
    "    \"\"\"Fetch top comments for a Reddit submission.\"\"\"\n",
    "    comments_data = []\n",
    "    submission.comments.replace_more(limit=0)  # Load all comments\n",
    "    comments = submission.comments.list()\n",
    "    for comment in comments:\n",
    "        if comment and hasattr(comment, 'body'):\n",
    "            comments_data.append({\n",
    "                'comment_body': comment.body,\n",
    "                'comment_author': str(comment.author) if comment.author else \"N/A\",\n",
    "                'comment_score': comment.score,\n",
    "                'comment_created_utc': comment.created_utc,\n",
    "                'comment_created_dt': convert_utc_to_datetime(comment.created_utc)\n",
    "            })\n",
    "    return comments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328deb33-83bd-4c48-a4fb-2d75436eab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reddit_data_from_urls(urls, max_comments_per_post=10, output_file=\"reddit_data.json\"):\n",
    "    \"\"\"Fetch Reddit data from a list of URLs.\"\"\"\n",
    "    posts_data = []\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Extract submission from the URL\n",
    "            submission = reddit.submission(url=url)\n",
    "            if submission and hasattr(submission, 'title'):\n",
    "                post = {\n",
    "                    'title': submission.title,\n",
    "                    'selftext': submission.selftext if submission.selftext else \"N/A\",\n",
    "                    'url': submission.url,\n",
    "                    'score': submission.score,\n",
    "                    'num_comments': submission.num_comments,\n",
    "                    'created_utc': submission.created_utc,\n",
    "                    'created_dt': convert_utc_to_datetime(submission.created_utc),\n",
    "                    'author': str(submission.author) if submission.author else \"N/A\",\n",
    "                    'subreddit': str(submission.subreddit),\n",
    "                    'comments': fetch_comments(submission, max_comments=max_comments_per_post)\n",
    "                }\n",
    "                posts_data.append(post)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for URL: {url}. Error: {e}\")\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(posts_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4862be87-b6d0-4014-bdda-597af807568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_data.json\n"
     ]
    }
   ],
   "source": [
    "# Fetch Reddit data from URLs and save to JSON\n",
    "fetch_reddit_data_from_urls(reddit_urls, max_comments_per_post=10, output_file=\"reddit_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc4a6a2-ee62-4afa-a894-13e414ca3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reddit_data_comments_from_urls(urls, output_file=\"reddit_data.json\"):\n",
    "    \"\"\"Fetch Reddit data from a list of URLs with all comments.\"\"\"\n",
    "    posts_data = []\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            # Extract submission from the URL\n",
    "            submission = reddit.submission(url=url)\n",
    "            if submission and hasattr(submission, 'title'):\n",
    "                post = {\n",
    "                    'title': submission.title,\n",
    "                    'selftext': submission.selftext if submission.selftext else \"N/A\",\n",
    "                    'url': submission.url,\n",
    "                    'score': submission.score,\n",
    "                    'num_comments': submission.num_comments,\n",
    "                    'created_utc': submission.created_utc,\n",
    "                    'created_dt': convert_utc_to_datetime(submission.created_utc),\n",
    "                    'author': str(submission.author) if submission.author else \"N/A\",\n",
    "                    'subreddit': str(submission.subreddit),\n",
    "                    'comments': fetch_comments(submission)  # Fetch all comments\n",
    "                }\n",
    "                posts_data.append(post)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for URL: {url}. Error: {e}\")\n",
    "\n",
    "    # Save the data to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(posts_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bc02bc5-a8b2-4a39-922c-8809b2d2c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to reddit_data_with_all_comments.json\n",
      "CPU times: total: 453 ms\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fetch Reddit data from URLs and save to JSON\n",
    "fetch_reddit_data_comments_from_urls(reddit_urls, output_file=\"reddit_data_with_all_comments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f82590-ed29-40e0-bb9c-41ef9dfe3b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

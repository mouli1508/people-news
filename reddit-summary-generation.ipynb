{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0db9fb88-c836-4e90-85f7-fdeead6ce9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import PromptTemplate\n",
    "import tiktoken\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c25c81d0-8a11-4303-af6d-80bfc348794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = 'AIzaSyD989utJ91F8wmJ8otxCKl5q_SUPR6Yd0Q'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e31bb68-232f-4c26-9437-a669fde6ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_info.input_token_limit=1000000\n",
      "model_info.output_token_limit=8192\n"
     ]
    }
   ],
   "source": [
    "model_info = genai.get_model(\"models/gemini-1.5-flash\")\n",
    "\n",
    "# Returns the \"context window\" for the model,\n",
    "# which is the combined input and output token limits.\n",
    "print(f\"{model_info.input_token_limit=}\")\n",
    "print(f\"{model_info.output_token_limit=}\")\n",
    "# ( input_token_limit=30720, output_token_limit=2048 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95d35d0-4ecd-462e-a36f-71f5eb04090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "def load_reddit_data(json_file):\n",
    "    \"\"\"Load the Reddit data from a JSON file.\"\"\"\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316f2463-96fc-4c03-830c-09fc2a5b5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data from the JSON\n",
    "def extract_reddit_text(data):\n",
    "    \"\"\"Extract titles, selftext, comments, and comment scores from the JSON data.\"\"\"\n",
    "    extracted_data = []\n",
    "    for post in data:\n",
    "        post_content = f\"Title: {post['title']}\\n\"\n",
    "        post_content += f\"Body: {post['selftext']}\\n\"\n",
    "        post_content += \"Comments:\\n\"\n",
    "        for comment in post.get(\"comments\", []):\n",
    "            if isinstance(comment, dict):  # Ensure it's a comment with score\n",
    "                post_content += f\"- {comment['comment_body']} (Score: {comment['comment_score']})\\n\"\n",
    "            else:\n",
    "                post_content += f\"- {comment}\\n\"\n",
    "        extracted_data.append(post_content)\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f759cf7-ac28-49d2-a25a-22e82f5ed501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tokens using the tokenizer\n",
    "def calculate_tokens(text_list, model_name=\"gemini-1.5-flash\"):\n",
    "    \"\"\"Calculate the number of tokens in a list of text inputs.\"\"\"\n",
    "    tokenizer = tiktoken.encoding_for_model(model_name)\n",
    "    total_tokens = 0\n",
    "\n",
    "    for text in text_list:\n",
    "        tokens = tokenizer.encode(text)\n",
    "        total_tokens += len(tokens)\n",
    "\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3188de30-967d-457b-be1d-f0ee89da84cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771b42c-f60a-47ec-8a02-aeee7ce84634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ab18f81-f36d-4f3f-9700-36c166649dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a summary using an LLM\n",
    "def generate_summary(extracted_data, context_question):\n",
    "    \"\"\"Generate a summary based on the context question using an LLM.\"\"\"\n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-flash\")\n",
    "    prompt = (\n",
    "        f\"The following is data extracted from Reddit. Based on the question below, \"\n",
    "        f\"generate a concise and accurate summary and final conclusion on the sentiment of the question based on whether it positive, negative or neutral:\\n\\n\"\n",
    "        f\"Question: {context_question}\\n\\n\"\n",
    "    )\n",
    "    for data in extracted_data:\n",
    "        prompt += f\"Post:\\n{data}\\n\\n\"\n",
    "\n",
    "    prompt += \"Provide a detailed summary:\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfef68-620b-422f-adb0-ad8c681aa946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c23bd717-5433-457d-b790-fc1a0e459ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the pipeline\n",
    "def summarize_reddit_data(json_file, question):\n",
    "    \"\"\"Load Reddit data, extract relevant text, and generate a summary.\"\"\"\n",
    "    data = load_reddit_data(json_file)\n",
    "    extracted_data = extract_reddit_text(data)\n",
    "    summary = generate_summary(extracted_data, question)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f46028d9-e4b3-4cfc-9710-e639e8c95c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The Reddit posts analyzed express overwhelmingly negative sentiment towards a potential Trump victory in the 2024 election.  The first post focuses on the anticipated impact on women's rights, with commenters predicting a significant rollback of reproductive rights, including potential bans on abortion and various forms of birth control, as well as restrictions on divorce.  The overall tone is one of fear and outrage, with many expressing anxieties about losing hard-won freedoms and a return to a more patriarchal society.  The second post explores the possibility of civil unrest or even civil war following the election, with a more divided opinion but a strong current of concern regarding the potential for violence and instability, particularly from the right if a Democrat wins. The third post discusses the perceived closeness of the election despite demographic trends seemingly favoring the Democrats. Commenters attribute this closeness to low youth voter turnout, the impact of the economy and inflation, the enduring power of misinformation, and strategic manipulation of electoral processes by the GOP.  The fourth post focuses specifically on Trump\\u2019s electability despite his felony conviction. While some believe the conviction might hinder his chances, others argue his strong base of support and the current political climate give him a viable shot at winning, particularly highlighting voter dissatisfaction with the current administration. The responses generally acknowledge the possibility of a narrow victory but express concern about potential implications, such as a disputed election outcome or further attempts to undermine democratic processes.  In each case, many commenters express deep concern over the potential outcomes of the election.\\n\\n**Final Conclusion:** The sentiment expressed across all four posts is predominantly negative.  While some commenters offer differing perspectives on the likelihood of specific outcomes, the overall tone is one of apprehension and alarm, reflecting a widespread fear of a Trump presidency and its potential consequences for democratic institutions, social progress, and civil liberties.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.6488903575762092\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 281289,\n",
      "        \"candidates_token_count\": 367,\n",
      "        \"total_token_count\": 281656\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reddit_json_file = 'reddit_data_with_all_comments.json'\n",
    "question = 'What people think on Trump winning the election'\n",
    "\n",
    "summary = summarize_reddit_data(reddit_json_file, question)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce879ce3-b7e2-4621-8ea0-d1f7af0649bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Reddit posts analyzed express overwhelmingly negative sentiment towards a potential Trump victory in the 2024 election.  The first post focuses on the anticipated impact on women's rights, with commenters predicting a significant rollback of reproductive rights, including potential bans on abortion and various forms of birth control, as well as restrictions on divorce.  The overall tone is one of fear and outrage, with many expressing anxieties about losing hard-won freedoms and a return to a more patriarchal society.  The second post explores the possibility of civil unrest or even civil war following the election, with a more divided opinion but a strong current of concern regarding the potential for violence and instability, particularly from the right if a Democrat wins. The third post discusses the perceived closeness of the election despite demographic trends seemingly favoring the Democrats. Commenters attribute this closeness to low youth voter turnout, the impact of the economy and inflation, the enduring power of misinformation, and strategic manipulation of electoral processes by the GOP.  The fourth post focuses specifically on Trump’s electability despite his felony conviction. While some believe the conviction might hinder his chances, others argue his strong base of support and the current political climate give him a viable shot at winning, particularly highlighting voter dissatisfaction with the current administration. The responses generally acknowledge the possibility of a narrow victory but express concern about potential implications, such as a disputed election outcome or further attempts to undermine democratic processes.  In each case, many commenters express deep concern over the potential outcomes of the election.\n",
      "\n",
      "**Final Conclusion:** The sentiment expressed across all four posts is predominantly negative.  While some commenters offer differing perspectives on the likelihood of specific outcomes, the overall tone is one of apprehension and alarm, reflecting a widespread fear of a Trump presidency and its potential consequences for democratic institutions, social progress, and civil liberties.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c98053-ffea-469b-b924-ef4744cbbe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

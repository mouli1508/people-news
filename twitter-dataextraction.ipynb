{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f9f00b-b9de-4635-ad5a-0e11b7a38218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntscraper import Nitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6717d4b-748c-4ffc-ac9e-03c0699e20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|█████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "scraper = Nitter(log_level=1, skip_instance_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8128f1-669a-49f1-8496-dafe3efeacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(keyword,no_of_tweets):\n",
    "  tweets = scraper.get_tweets(keyword, mode='term', number=no_of_tweets)\n",
    "  data = {\n",
    "      'keyword' :[],\n",
    "      'date' :[],\n",
    "      'link' :[],\n",
    "      'pictures' :[],\n",
    "      'replying-to' :[],\n",
    "      'comments' :[],\n",
    "      'likes' :[],\n",
    "      'quotes' :[],\n",
    "      'retweets' :[],\n",
    "      'text' :[],\n",
    "      'user' :[]\n",
    "    }\n",
    "\n",
    "  for tweet in tweets['tweets']:\n",
    "    data['keyword'].append(keyword)\n",
    "    data['date'].append(tweet['date'])\n",
    "    data['link'].append(tweet['link'])\n",
    "    data['pictures'].append(tweet['pictures'])\n",
    "    data['replying-to'].append(tweet['replying-to'])\n",
    "    data['comments'].append(tweet['stats']['comments'])\n",
    "    data['likes'].append(tweet['stats']['likes'])\n",
    "    data['quotes'].append(tweet['stats']['quotes'])\n",
    "    data['retweets'].append(tweet['stats']['retweets'])\n",
    "    data['text'].append(tweet['text'])\n",
    "    data['user'].append(tweet['user']['username'])\n",
    "\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "def create_tweet_dataset(keywords, num_tweets, output_file):\n",
    "  combined_data = pd.DataFrame()\n",
    "\n",
    "  for key in keywords:\n",
    "    print(f\"Extracting tweets for keyword: {key}\")\n",
    "    keyword_data = extract_tweets(key, num_tweets)\n",
    "\n",
    "        # Append to the combined DataFrame\n",
    "    combined_data = pd.concat([combined_data, keyword_data], ignore_index=True)\n",
    "\n",
    "  combined_data.to_csv(output_file, index=False)\n",
    "  print(f\"Data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc61081-99ef-4221-8892-48908547ae19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tweets for keyword: Europe\n",
      "11-Nov-24 16:11:48 - No instance specified, using random instance https://nitter.privacydev.net\n",
      "11-Nov-24 16:11:48 - Empty page on https://nitter.privacydev.net\n",
      "Data saved to data.csv\n"
     ]
    }
   ],
   "source": [
    "keywords = ['Europe']\n",
    "num_tweets = 10\n",
    "output_file = \"data.csv\"\n",
    "\n",
    "create_tweet_dataset(keywords, num_tweets, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c9ec4d-3fa0-4583-b949-65d92d56a241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>pictures</th>\n",
       "      <th>replying-to</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [keyword, date, link, pictures, replying-to, comments, likes, quotes, retweets, text, user]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34f1b1-183d-464f-b37f-2773122aa156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
